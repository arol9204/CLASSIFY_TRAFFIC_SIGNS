{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPSUxWrxL5+f4EIZOpzBwhZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arol9204/arol9204/blob/main/English_Speaking_AI_examiner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain and LLM dolly"
      ],
      "metadata": {
        "id": "dIB1FJGALWVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain"
      ],
      "metadata": {
        "id": "rZjaGV72_wNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install \"transformers[torch]\""
      ],
      "metadata": {
        "id": "Mbt8ui74AEeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "# databricks/dolly-v2-3b\n",
        "# databricks/dolly-v2-7b\n",
        "# databricks/dolly-v2-2-8b\n",
        "# databricks/dolly-v2-12b\n",
        "\n",
        "# OpenAssistant/falcon-7b-sft-mix-2000\n",
        "# OpenAssistant/falcon-40b-sft-mix-1226\n",
        "\n",
        "\n",
        "generate_text = pipeline(model=\"databricks/dolly-v2-3b\",\n",
        "                         torch_dtype=torch.bfloat16,\n",
        "                         trust_remote_code=True,\n",
        "                         device_map=\"auto\",\n",
        "                         return_full_text=True)"
      ],
      "metadata": {
        "id": "IzeaknCwAIuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.llms import HuggingFacePipeline"
      ],
      "metadata": {
        "id": "zknNSN22AM99"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Whisper for speaking-to-text trasncript"
      ],
      "metadata": {
        "id": "sYKqSgkuAsSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the latest commit from Github whisper repository\n",
        "! pip install git+https://github.com/openai/whisper.git -q"
      ],
      "metadata": {
        "id": "u9N9yfQZA0Wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing command-line tool ffmpeg\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "id": "vn8AnWuMA0Q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install the Web UI Toolkit"
      ],
      "metadata": {
        "id": "TbaqFY6ffcg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gradio -q"
      ],
      "metadata": {
        "id": "Gh0-aXM2_xd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The App"
      ],
      "metadata": {
        "id": "BTJ36HVnkMjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import gradio as gr\n",
        "import time"
      ],
      "metadata": {
        "id": "WrWXVn8-CyHp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_pipeline = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "English_review_template = \"\"\"You are a professional examiner who assesses the English language proficiency of candidates taking an English test.\n",
        "You asked this question: {question} \\\n",
        "The answer was: {text}.\n",
        "\n",
        "Evaluate the answer based on the following criteria:\\\n",
        "\n",
        "- Coherence: Assess how well the candidate's answer is connected to the question.\n",
        "- Word Choice: Assess if the candidate uses appropriate words and phrases to communicate.\n",
        "- Vocabulary Range: Assess if the candidate uses a variety of vocabulary.\n",
        "- Sentence Structure: Assess the candidate's ability to use a variety of sentence structures appropriately.\n",
        "- Grammatical Accuracy: Explain how well did the candidate formed grammatically correct sentences?\n",
        "- Grammatical Errors: List and explain each grammar error in the candidate's answer.\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate.from_template(English_review_template)\n",
        "\n",
        "llm_chain = LLMChain(llm=hf_pipeline, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "eSwrq56kOidq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def English_feedback(Question, audio):\n",
        "  model = whisper.load_model(\"base\")\n",
        "  text = model.transcribe(audio)\n",
        "  response = llm_chain.run({'text': text, 'question': Question})\n",
        "  return text[\"text\"], response"
      ],
      "metadata": {
        "id": "TlbWowbE_yJ4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(\n",
        "    title = 'English Speaking AI-examiner ',\n",
        "    fn=English_feedback,\n",
        "    inputs=[\"text\", gr.inputs.Audio(source=\"microphone\", type=\"filepath\")],\n",
        "    outputs=[ \"textbox\", \"textbox\"])\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "9h5X63sW7jSw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "4a5a90c0-f6e2-47aa-829b-1e317f5f523c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:321: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:324: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  super().__init__(source=source, type=type, label=label, optional=optional)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://36cc0b01d46f636bf6.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://36cc0b01d46f636bf6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4RHxuKWbCzz3"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}